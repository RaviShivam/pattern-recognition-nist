{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "def to_csv(name, x, y, z):\n",
    "    df = pd.DataFrame(z, index=y, columns=x)  # 1st row as the column names\n",
    "    df.to_csv(\"experiment-results/\"+name, encoding='utf-8', sep=',')\n",
    "\n",
    "\n",
    "def get_raw_pixels(full_data=True):\n",
    "    df = pd.read_csv('data/processed_nist_data.csv', sep=',', header=None)\n",
    "    if full_data:\n",
    "        df = df.as_matrix()\n",
    "        X, y = df[:, 1:], df[:, 0]\n",
    "        X_train, X_validate, y_train, y_validate = train_test_split(X, y, train_size=0.8, shuffle=True)\n",
    "    else:\n",
    "        df = df.sample(frac=1).reset_index(drop=True)  # shuffle data\n",
    "        df = df.groupby(0)\n",
    "        df100 = df.apply(lambda x: x.sample(frac=0.01)).as_matrix()\n",
    "        X_train, y_train = df100[:, 1:], df100[:, 0]\n",
    "        df1000 = df.apply(lambda x: x.sample(frac=0.1)).as_matrix()\n",
    "        X_validate, y_validate = df1000[:, 1:], df1000[:, 0]\n",
    "\n",
    "    return X_train, X_validate, y_train, y_validate\n",
    "\n",
    "\n",
    "def experimentPCA_fulldata(classifier, X_train, X_validate, y_train, y_validate, filename=None, show_results=False, n_comp_auto=False):\n",
    "    performance = {}\n",
    "\n",
    "    if not n_comp_auto:\n",
    "        for n_comp in range(1, 30):\n",
    "            print(\"processing c=\", n_comp)\n",
    "            pca = PCA(n_components=n_comp)\n",
    "            classifier.fit(pca.fit_transform(X_train), y_train)\n",
    "            performance[n_comp] = accuracy_score(y_validate, classifier.predict(pca.transform(X_validate)))\n",
    "        handle_plot(performance, show_results, filename)\n",
    "    else:\n",
    "        pca = PCA()\n",
    "        pca.fit(X_train)\n",
    "        variance = pca.explained_variance_\n",
    "        n_comp = max(np.argwhere(variance > 0.9))[0]\n",
    "        pca.n_components = n_comp\n",
    "        classifier.fit(pca.fit_transform(X_train), y_train)\n",
    "        performance[0] = accuracy_score(y_validate, classifier.predict(pca.transform(X_validate)))\n",
    "\n",
    "    return performance, n_comp\n",
    "\n",
    "\n",
    "def handle_plot(performance, show_results, filename):\n",
    "    fig = plt.figure()\n",
    "    plt.title('Number of Components Retained vs Performance')\n",
    "    plt.xlabel('Number of Components')\n",
    "    plt.ylabel('Accuracy (%)')\n",
    "\n",
    "    plt.plot(performance.keys(), performance.values())\n",
    "    if show_results:\n",
    "        plt.show()\n",
    "    if filename:\n",
    "        pp = PdfPages(\"experiment-results/\" + filename + \".pdf\")\n",
    "        pp.savefig(fig)\n",
    "        pp.close()\n",
    "        \n",
    "        \n",
    "def get_max_from_dict(x):\n",
    "    max_key = max(x.keys(), key=(lambda key: x[key]))\n",
    "    # print(max_key)\n",
    "    # print(x.get(max_key))\n",
    "    return max_key, x.get(max_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({0: 84.399999999999991}, 33)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import pr_utils\n",
    "\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(330, 85), max_iter=150, alpha=1e-5,\n",
    "                    solver='lbfgs', tol=1e-4, random_state=1,\n",
    "                    learning_rate_init=.1)\n",
    "\n",
    "experimentPCA_fulldata(mlp, full_data=False, filename=\"NN_330_85_batch\", show_results=True, n_comp_auto=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib import cm\n",
    "from matplotlib.ticker import LinearLocator, FormatStrFormatter\n",
    "\n",
    "def plot3d(X, Y, Z, name=None):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.gca(projection='3d')\n",
    "\n",
    "    # print(X.shape)\n",
    "    # print(Y.shape)\n",
    "    X, Y = np.meshgrid(X, Y)\n",
    "    # print(Z.shape)\n",
    "\n",
    "    # Plot the surface.\n",
    "    surf = ax.plot_surface(X, Y, Z, cmap=cm.coolwarm,\n",
    "                           linewidth=0, antialiased=False,\n",
    "                           vmin=0.4, vmax=1)\n",
    "    \n",
    "    # Customize the z axis.\n",
    "    ax.set_zlim(0.4, 1)\n",
    "    ax.zaxis.set_major_locator(LinearLocator(10))\n",
    "    ax.zaxis.set_major_formatter(FormatStrFormatter('%.02f'))\n",
    "\n",
    "    # Customize descriptions\n",
    "    ax.set_xlabel('Hidden layer #1 size')\n",
    "    ax.set_ylabel('Hidden layer #2 size')\n",
    "    ax.set_zlabel('Accuracy')\n",
    "    plt.title(\"Performance depending on size of hidden layers\")\n",
    "\n",
    "    # Add a color bar which maps values to colors.\n",
    "    fig.colorbar(surf, shrink=0.5, aspect=5)\n",
    "    if name:\n",
    "        plt.savefig(\"experiment-results/\" + name + \".png\", dpi=400)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "import pr_utils\n",
    "\n",
    "def tune_layer_size(pca=False, full_data=False):\n",
    "    if pca:\n",
    "        layer1_step = 2\n",
    "        layer2_step = 2\n",
    "        layer1_start = 20\n",
    "        layer1_stop = 90\n",
    "        layer2_start = 11\n",
    "        layer2_stop = 60\n",
    "    else:\n",
    "        layer1_step = 10\n",
    "        layer2_step = 5\n",
    "        layer1_start = 100\n",
    "        layer1_stop = 400\n",
    "        layer2_start = 15\n",
    "        layer2_stop = 100\n",
    "\n",
    "    X_train, X_validate, y_train, y_validate = pr_utils.get_raw_pixels(full_data)\n",
    "\n",
    "    results = {}\n",
    "    res_layer2 = np.arange(layer2_start, layer2_stop, layer2_step)\n",
    "    res_layer1 = np.arange(layer1_start, layer1_stop, layer1_step)\n",
    "    res = np.zeros((res_layer2.shape[0], res_layer1.shape[0]))\n",
    "\n",
    "    layer2_index = 0\n",
    "    for layer2 in range(layer2_start, layer2_stop, layer2_step):\n",
    "        # print(\"progress\", (((layer2 - layer2_start) / layer2_step) + 1) / ((layer2_stop - layer2_start) / layer2_step))\n",
    "        layer1_index = 0\n",
    "        for layer1 in range(layer1_start, layer1_stop, layer1_step):\n",
    "            mlp = MLPClassifier(hidden_layer_sizes=(layer1, layer2), max_iter=150, alpha=1e-5,\n",
    "                                solver='lbfgs', tol=1e-4, random_state=1,\n",
    "                                learning_rate_init=.1)\n",
    "            if pca:\n",
    "                acc, com = experimentPCA_fulldata(mlp, X_train, X_validate, y_train, y_validate, n_comp_auto=True)\n",
    "                acc = acc[0]\n",
    "            else:\n",
    "                mlp.fit(X_train, y_train)\n",
    "                acc = metrics.accuracy_score(y_validate, mlp.predict(X_validate))\n",
    "\n",
    "            # acc = np.random.rand()/2+0.4\n",
    "\n",
    "            results[(layer1, layer2)] = acc\n",
    "            res[layer2_index][layer1_index] = acc\n",
    "\n",
    "            layer1_index += 1\n",
    "        layer2_index += 1\n",
    "\n",
    "    return res_layer1, res_layer2, res, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_full_nn_experiment(name, pca, full_data):\n",
    "    X, Y, Z, total_results = tune_layer_size(pca=pca, full_data=full_data)\n",
    "    plot3d(X, Y, Z, name=name)\n",
    "    to_csv(\"res_\" + name, X, Y, Z)\n",
    "    print(\"max:\", get_max_from_dict(total_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running nn_opt_layers-full\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\motos\\machine_learning\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "print(\"running nn_opt_layers-full\")\n",
    "run_full_nn_experiment(\"nn_opt_layers-full\", pca=False, full_data=True)\n",
    "print(\"done after\", time.time()-start)\n",
    "checkpoint = time.time()\n",
    "\n",
    "print(\"running nn_opt_layers-batch\")\n",
    "run_full_nn_experiment(\"nn_opt_layers-batch\", pca=False, full_data=False)\n",
    "print(\"done after\", time.time()-checkpoint)\n",
    "checkpoint = time.time()\n",
    "\n",
    "print(\"running nn_opt_layers-full_pca\")\n",
    "run_full_nn_experiment(\"nn_opt_layers-full_pca\", pca=True, full_data=True)\n",
    "print(\"done after\", time.time()-checkpoint)\n",
    "checkpoint = time.time()\n",
    "\n",
    "print(\"running nn_opt_layers-batch_pca\")\n",
    "run_full_nn_experiment(\"nn_opt_layers-batch_pca\", pca=True, full_data=False)\n",
    "print(\"done after\", time.time()-checkpoint)\n",
    "checkpoint = time.time()\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(\"omg, the end. total time=\", end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running nn_opt_layers-batch_pca\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35,) (25,) (25, 35) 875\ndone after 74.82157468795776\n"
     ]
    }
   ],
   "source": [
    "print(\"running nn_opt_layers-batch_pca\")\n",
    "checkpoint = time.time()\n",
    "run_full_nn_experiment(\"nn_opt_layers-batch_pca\", pca=True, full_data=False)\n",
    "print(\"done after\", time.time()-checkpoint)\n",
    "checkpoint = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}